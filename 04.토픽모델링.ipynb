{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e936ec0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bertopic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbertopic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BERTopic\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkonlpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Okt\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bertopic'"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Okt\n",
    "import os\n",
    "# --- 데이터 준비 ---\n",
    "# 1. 전처리된 텍스트 로드\n",
    "preprocessed_text_dir = '법령_전처리_텍스트'\n",
    "docs = []\n",
    "law_names_for_topic = []\n",
    "for filename in os.listdir(preprocessed_text_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        law_names_for_topic.append(filename[:-4])\n",
    "        with open(os.path.join(preprocessed_text_dir, filename), 'r', encoding='utf-8') as f:\n",
    "            docs.append(f.read())\n",
    "\n",
    "# 2. 분석 대상 그룹 정의 (변호사 시험 과목 기준)\n",
    "# (public_laws, civil_laws, criminal_laws 리스트가 메모리에 있다고 가정)\n",
    "law_to_subject = {law: '공법' for law in public_laws}\n",
    "law_to_subject.update({law: '민사법' for law in civil_laws})\n",
    "law_to_subject.update({law: '형사법' for law in criminal_laws})\n",
    "\n",
    "# --- 토픽 모델링 실행 ---\n",
    "# 1. 한국어 명사 추출을 위한 벡터라이저 설정\n",
    "okt = Okt()\n",
    "vectorizer = CountVectorizer(tokenizer=okt.nouns, max_features=3000)\n",
    "\n",
    "# 2. BERTopic 모델 초기화\n",
    "# min_topic_size: 토픽을 구성하기 위한 최소 문서(법령) 수\n",
    "topic_model = BERTopic(embedding_model=\"jhgan/ko-sbert-nli\",\n",
    "                       vectorizer_model=vectorizer,\n",
    "                       min_topic_size=5,\n",
    "                       verbose=True)\n",
    "\n",
    "# 3. 모델 학습 및 토픽 추출\n",
    "# 시간이 매우 오래 걸릴 수 있습니다. ⏳\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "# 4. 결과 확인\n",
    "print(\"\\n--- BERTopic 분석 결과 ---\")\n",
    "# 가장 자주 등장하는 토픽들\n",
    "print(topic_model.get_topic_info())\n",
    "\n",
    "# 특정 토픽의 키워드 확인 (예: 0번 토픽)\n",
    "print(\"\\n--- 0번 토픽의 주요 키워드 ---\")\n",
    "print(topic_model.get_topic(0))\n",
    "\n",
    "# --- 그룹별 토픽 분석 ---\n",
    "# 1. 각 법령에 토픽 ID와 과목 정보 추가\n",
    "df_topics = topic_model.get_document_info(docs, law_names_for_topic)\n",
    "df_topics['과목'] = df_topics['Name'].map(law_to_subject).fillna('기타')\n",
    "\n",
    "# 2. 각 과목 그룹별로 어떤 토픽이 주로 나타나는지 시각화\n",
    "# 이 시각화는 Jupyter Notebook 환경에서 가장 잘 보입니다.\n",
    "fig = topic_model.visualize_topics_by_class(\n",
    "    df_topics,\n",
    "    top_n_topics=10, # 상위 10개 토픽만 시각화\n",
    "    custom_labels=True\n",
    ")\n",
    "fig.show() # 대화형 차트 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7169fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
