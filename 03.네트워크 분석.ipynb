{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e20dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'법령_통합텍스트(현역)' 폴더에서 원본 법령 텍스트를 로드합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5502/5502 [00:00<00:00, 6884.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "데이터 로딩 완료: 총 5502개 법령\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 원본 텍스트가 저장된 디렉토리\n",
    "original_text_dir = '법령_통합텍스트(현역)'\n",
    "all_laws_data = []\n",
    "\n",
    "print(f\"'{original_text_dir}' 폴더에서 원본 법령 텍스트를 로드합니다...\")\n",
    "for filename in tqdm(os.listdir(original_text_dir)):\n",
    "    if filename.endswith('.txt'):\n",
    "        law_name = filename[:-4]\n",
    "        file_path = os.path.join(original_text_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        all_laws_data.append({\n",
    "            '법령명': law_name,\n",
    "            '내용': content\n",
    "        })\n",
    "\n",
    "df_laws = pd.DataFrame(all_laws_data)\n",
    "# 전체 법령 이름 리스트를 미리 생성 (검색에 사용)\n",
    "law_names_list = df_laws['법령명'].tolist()\n",
    "\n",
    "print(f\"\\n데이터 로딩 완료: 총 {len(df_laws)}개 법령\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8d80f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "법령 간 인용 관계를 추출합니다... (시간이 소요될 수 있습니다)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5502/5502 [02:44<00:00, 33.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "총 74158개의 인용 관계(엣지)를 발견했습니다.\n",
      "             source       target  weight\n",
      "61524  지방세특례제한법 시행령      조세특례제한법     318\n",
      "57196   조세특례제한법 시행령         소득세법     302\n",
      "61525  지방세특례제한법 시행령  조세특례제한법 시행령     300\n",
      "56895       조세특례제한법         소득세법     290\n",
      "57148   조세특례제한법 시행령         법인세법     286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "edges = []\n",
    "print(\"\\n법령 간 인용 관계를 추출합니다... (시간이 소요될 수 있습니다)\")\n",
    "\n",
    "# 각 법령을 순회 (source)\n",
    "for index, row in tqdm(df_laws.iterrows(), total=df_laws.shape[0]):\n",
    "    source_name = row['법령명']\n",
    "    source_text = row['내용']\n",
    "\n",
    "    # 다른 모든 법령을 검색 (target)\n",
    "    for target_name in law_names_list:\n",
    "        # 자기 자신을 인용하는 경우는 제외\n",
    "        if source_name == target_name:\n",
    "            continue\n",
    "        \n",
    "        # 텍스트에서 다른 법령 이름이 언급된 횟수를 카운트\n",
    "        count = source_text.count(target_name)\n",
    "        \n",
    "        # 한 번이라도 언급되었다면 엣지 리스트에 추가\n",
    "        if count > 0:\n",
    "            edges.append({\n",
    "                'source': source_name,\n",
    "                'target': target_name,\n",
    "                'weight': count\n",
    "            })\n",
    "\n",
    "# 엣지 리스트를 데이터프레임으로 변환\n",
    "df_edges = pd.DataFrame(edges)\n",
    "\n",
    "print(f\"\\n총 {len(df_edges)}개의 인용 관계(엣지)를 발견했습니다.\")\n",
    "print(df_edges.sort_values(by='weight', ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950bada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "네트워크 생성 완료: 노드 5502개, 엣지 74158개\n",
      "law_citation_network.html\n",
      "\n",
      "'law_citation_network.html'으로 인터랙티브 네트워크 시각화가 저장되었습니다.\n",
      "생성된 html 파일을 웹 브라우저로 열어 확인해보세요!\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "# 방향성이 있는 그래프(DiGraph) 생성\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# 모든 법령을 노드로 추가\n",
    "G.add_nodes_from(law_names_list)\n",
    "\n",
    "# 데이터프레임에서 엣지 정보를 읽어와 가중치가 있는 엣지로 추가\n",
    "# (source, target, weight) 형태의 튜플 리스트로 변환하여 전달\n",
    "edge_tuples = [tuple(x) for x in df_edges.to_numpy()]\n",
    "G.add_weighted_edges_from(edge_tuples)\n",
    "\n",
    "print(f\"\\n네트워크 생성 완료: 노드 {G.number_of_nodes()}개, 엣지 {G.number_of_edges()}개\")\n",
    "\n",
    "# Pyvis 네트워크 객체 생성\n",
    "net = Network(height='800px', width='100%', notebook=True, directed=True, cdn_resources='in_line')\n",
    "\n",
    "# NetworkX 그래프를 Pyvis 그래프로 변환\n",
    "net.from_nx(G)\n",
    "\n",
    "# 네트워크 시각화 옵션 설정\n",
    "net.show_buttons(filter_=['physics'])\n",
    "# net.force_atlas_2based(gravity=-50, central_gravity=0.01, spring_length=100) # 레이아웃 옵션\n",
    "\n",
    "# HTML 파일로 저장 및 출력\n",
    "output_filename = \"law_citation_network.html\"\n",
    "net.show(output_filename)\n",
    "\n",
    "print(f\"\\n'{output_filename}'으로 인터랙티브 네트워크 시각화가 저장되었습니다.\")\n",
    "print(\"생성된 html 파일을 웹 브라우저로 열어 확인해보세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "626028b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- 가장 많이 인용되는 법령 TOP 10 (In-Degree) ---\n",
      "            법령명  In-Degree\n",
      "             민법       1327\n",
      "공공기관의 운영에 관한 법률       1171\n",
      "          전자정부법       1086\n",
      "       개인정보 보호법       1050\n",
      "          고등교육법        998\n",
      "             형법        917\n",
      "   개인정보 보호법 시행령        626\n",
      "        초ㆍ중등교육법        525\n",
      "             상법        507\n",
      "            건축법        498\n",
      "\n",
      "\n",
      "--- 영향력이 가장 높은 법령 TOP 10 (PageRank) ---\n",
      "            법령명  PageRank\n",
      "             형법  0.026341\n",
      "             민법  0.026082\n",
      "공공기관의 운영에 관한 법률  0.015025\n",
      "          민사소송법  0.014460\n",
      "          고등교육법  0.012180\n",
      "          민사집행법  0.011820\n",
      "             상법  0.011486\n",
      "         국가공무원법  0.010215\n",
      "       개인정보 보호법  0.008357\n",
      "          전자정부법  0.007259\n",
      "\n",
      "\n",
      "--- '허브' 역할을 하는 법령 TOP 10 (Betweenness) ---\n",
      "                           법령명  Betweenness\n",
      "                      지방세특례제한법     0.054351\n",
      "                  대기환경보전법 시행규칙     0.046298\n",
      "           기업활동 규제완화에 관한 특별조치법     0.046205\n",
      "              산업입지 및 개발에 관한 법률     0.044713\n",
      "                   조세특례제한법 시행령     0.035525\n",
      "                       조세특례제한법     0.028223\n",
      "                  건설기계관리법 시행규칙     0.024689\n",
      "제주특별자치도 설치 및 국제자유도시 조성을 위한 특별법     0.023272\n",
      "          행정권한의 위임 및 위탁에 관한 규정     0.020147\n",
      "       산업교육진흥 및 산학연협력촉진에 관한 법률     0.018819\n"
     ]
    }
   ],
   "source": [
    "# 1. 연결 중심성 (Degree Centrality): 가장 많이 연결된 법령\n",
    "# In-degree: 다른 법령으로부터 가장 많이 인용'되는' 법령\n",
    "in_degree = G.in_degree(weight='weight')\n",
    "df_in_degree = pd.DataFrame(in_degree, columns=['법령명', 'In-Degree']).sort_values(by='In-Degree', ascending=False)\n",
    "\n",
    "print(\"\\n\\n--- 가장 많이 인용되는 법령 TOP 10 (In-Degree) ---\")\n",
    "print(df_in_degree.head(10).to_string(index=False))\n",
    "\n",
    "# 2. 페이지랭크 (PageRank): 구글 검색처럼 중요도/영향력이 높은 법령\n",
    "pagerank = nx.pagerank(G, weight='weight')\n",
    "df_pagerank = pd.DataFrame(pagerank.items(), columns=['법령명', 'PageRank']).sort_values(by='PageRank', ascending=False)\n",
    "\n",
    "print(\"\\n\\n--- 영향력이 가장 높은 법령 TOP 10 (PageRank) ---\")\n",
    "print(df_pagerank.head(10).to_string(index=False))\n",
    "\n",
    "# 3. 매개 중심성 (Betweenness Centrality): 법령들을 연결하는 '허브/가교' 역할을 하는 법령\n",
    "betweenness = nx.betweenness_centrality(G, weight='weight')\n",
    "df_betweenness = pd.DataFrame(betweenness.items(), columns=['법령명', 'Betweenness']).sort_values(by='Betweenness', ascending=False)\n",
    "\n",
    "print(\"\\n\\n--- '허브' 역할을 하는 법령 TOP 10 (Betweenness) ---\")\n",
    "print(df_betweenness.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa70d37",
   "metadata": {},
   "source": [
    "### 커뮤니티 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bff841b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네트워크 커뮤니티 탐지를 시작합니다 (루뱅 알고리즘)...\n",
      "총 193개의 커뮤니티를 발견했습니다.\n",
      "\n",
      "커뮤니티 분석 결과와 변호사 시험 과목 정보를 병합했습니다.\n",
      "\n",
      "--- 커뮤니티 분석 결과 (상위 10개) ---\n",
      "                                      법령명  커뮤니티ID  과목\n",
      "0  4ㆍ16세월호참사 진상규명 및 안전사회 건설 등을 위한 특별법 시행령       0  기타\n",
      "1               4차산업혁명위원회의 설치 및 운영에 관한 규정       1  기타\n",
      "2                     각병과사병의군사경찰직무보조에관한규정       2  기타\n",
      "3                        감사원규칙의 공포에 관한 규칙       3  기타\n",
      "4                          감사원 정책자문위원회 규칙       4  기타\n",
      "5               거창사건등 관련자의 명예회복에 관한 특별조치법       5  기타\n",
      "6                            검사 선서에 관한 규정       6  기타\n",
      "7                           검사의 법복에 관한 규칙       7  기타\n",
      "8            경기도 수원시와 용인시의 관할구역 변경에 관한 규정       8  기타\n",
      "9            경기도 수원시와 화성시의 관할구역 변경에 관한 규정       9  기타\n",
      "\n",
      "--- 각 커뮤니티별 크기 및 과목 분포 ---\n",
      "과목      공법  기타  민사법  형사법\n",
      "커뮤니티ID                  \n",
      "0        0   1    0    0\n",
      "1        0   1    0    0\n",
      "2        0   1    0    0\n",
      "3        0   1    0    0\n",
      "4        0   1    0    0\n",
      "...     ..  ..  ...  ...\n",
      "188      0   1    0    0\n",
      "189      0   1    0    0\n",
      "190      0   1    0    0\n",
      "191      0   2    0    0\n",
      "192      0   1    0    0\n",
      "\n",
      "[193 rows x 4 columns]\n",
      "\n",
      "--- 0번 커뮤니티에 속한 법령 목록 (일부) ---\n",
      "['4ㆍ16세월호참사 진상규명 및 안전사회 건설 등을 위한 특별법 시행령']\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "import pandas as pd\n",
    "\n",
    "# 이전에 생성한 네트워크 그래프 G가 있다고 가정합니다.\n",
    "# 만약 없다면, 이전 단계의 코드를 실행하여 G를 먼저 생성해야 합니다.\n",
    "# G = nx.from_pandas_edgelist(df_edges, source='source', target='target', edge_attr='weight', create_using=nx.DiGraph())\n",
    "\n",
    "print(\"네트워크 커뮤니티 탐지를 시작합니다 (루뱅 알고리즘)...\")\n",
    "\n",
    "# 1. 커뮤니티 탐지 실행\n",
    "# 방향성이 없는 그래프로 변환하여 커뮤니티 탐지 (더 일반적)\n",
    "G_undirected = G.to_undirected()\n",
    "communities = community.louvain_communities(G_undirected, weight='weight')\n",
    "print(f\"총 {len(communities)}개의 커뮤니티를 발견했습니다.\")\n",
    "\n",
    "# 2. 각 노드가 어떤 커뮤니티에 속하는지 매핑\n",
    "community_map = {}\n",
    "for i, comm in enumerate(communities):\n",
    "    for law_name in comm:\n",
    "        community_map[law_name] = i\n",
    "\n",
    "# 3. 결과를 데이터프레임으로 변환\n",
    "df_community = pd.DataFrame(community_map.items(), columns=['법령명', '커뮤니티ID'])\n",
    "\n",
    "# 4. 변호사 시험 과목 정보와 병합 (비교 분석을 위해)\n",
    "try:\n",
    "    public_laws = pd.read_csv('변호사시험_출제대상_부속법령(공법).csv', sep='\\t')['법령명'].tolist()\n",
    "    civil_laws = pd.read_csv('변호사시험_출제대상_부속법령(민사법).csv', sep='\\t')['법령명'].tolist()\n",
    "    criminal_laws = pd.read_csv('변호사시험_출제대상_부속법령(형사법).csv', sep='\\t')['법령명'].tolist()\n",
    "\n",
    "    def get_subject(law):\n",
    "        if law in public_laws: return '공법'\n",
    "        if law in civil_laws: return '민사법'\n",
    "        if law in criminal_laws: return '형사법'\n",
    "        return '기타'\n",
    "\n",
    "    df_community['과목'] = df_community['법령명'].apply(get_subject)\n",
    "    print(\"\\n커뮤니티 분석 결과와 변호사 시험 과목 정보를 병합했습니다.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n(참고) 변호사 시험 과목 파일을 찾을 수 없어 과목 정보는 추가되지 않았습니다.\")\n",
    "\n",
    "\n",
    "# 5. 결과 확인\n",
    "print(\"\\n--- 커뮤니티 분석 결과 (상위 10개) ---\")\n",
    "print(df_community.head(10))\n",
    "\n",
    "# 각 커뮤니티의 크기와 주요 과목 분포 확인\n",
    "print(\"\\n--- 각 커뮤니티별 크기 및 과목 분포 ---\")\n",
    "print(df_community.groupby('커뮤니티ID')['과목'].value_counts().unstack(fill_value=0))\n",
    "\n",
    "# 특정 커뮤니티에 속한 법령 목록 확인 (예: 0번 커뮤니티)\n",
    "print(\"\\n--- 0번 커뮤니티에 속한 법령 목록 (일부) ---\")\n",
    "print(df_community[df_community['커뮤니티ID'] == 0]['법령명'].tolist()[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf9b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. 최종 결과 저장 (이 부분을 추가) ---\n",
    "output_filename = '커뮤니티 탐지(현역).csv'\n",
    "df_community.to_csv(output_filename, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842dd828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\silve\\miniconda3\\envs\\bylaw\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-08-01 20:26:36,201 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Batches: 100%|██████████| 47/47 [00:02<00:00, 18.02it/s]\n",
      "2025-08-01 20:26:59,666 - BERTopic - Embedding - Completed ✓\n",
      "2025-08-01 20:26:59,666 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-08-01 20:27:06,259 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-08-01 20:27:06,262 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-08-01 20:27:06,280 - BERTopic - Cluster - Completed ✓\n",
      "2025-08-01 20:27:06,280 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-08-01 20:29:05,455 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BERTopic 분석 결과 ---\n",
      "    Topic  Count               Name  \\\n",
      "0      -1    298     -1_경우_사항_해당_청구   \n",
      "1       0     47      0_금융_투자_회사_집합   \n",
      "2       1     45  1_해양수산부_어업_수산물_수산   \n",
      "3       2     39    2_학교_교육_교육감_교육부   \n",
      "4       3     35     3_기금_보조금_재정_회계   \n",
      "..    ...    ...                ...   \n",
      "80     79      6    79_건설_기계_승강기_공사   \n",
      "81     80      6   80_조합_중앙회_부실_조합원   \n",
      "82     81      6    81_도서관_대학_자료_학교   \n",
      "83     82      6     82_보험_회사_계약_손해   \n",
      "84     83      5   83_건축_건축물_건축사_해체   \n",
      "\n",
      "                                       Representation  \\\n",
      "0            [경우, 사항, 해당, 청구, 개정, 장관, 기관, 호의, 다음, 산업]   \n",
      "1            [금융, 투자, 회사, 집합, 증권, 은행, 신탁, 발행, 주식, 거래]   \n",
      "2   [해양수산부, 어업, 수산물, 수산, 식품, 어촌, 농림축산식품부, 인증, 농산물,...   \n",
      "3     [학교, 교육, 교육감, 교육부, 교원, 학생, 평생교육, 대학, 학교법인, 유치원]   \n",
      "4           [기금, 보조금, 재정, 회계, 지출, 운용, 지방, 후원, 교부, 예산]   \n",
      "..                                                ...   \n",
      "80    [건설, 기계, 승강기, 공사, 발주, 수급인, 국토교통부, 하도급, 부품, 사업자]   \n",
      "81         [조합, 중앙회, 부실, 조합원, 예금, 기금, 총회, 임원, 정관, 관리]   \n",
      "82          [도서관, 대학, 자료, 학교, 문화, 운영, 지방, 지식, 국립, 설립]   \n",
      "83          [보험, 회사, 계약, 손해, 보험금, 금융, 예금, 모집, 상법, 재해]   \n",
      "84      [건축, 건축물, 건축사, 해체, 민간, 점검, 주무, 국토교통부, 투자, 사업]   \n",
      "\n",
      "                                  Representative_Docs  \n",
      "0   [총칙 목적 지방자치단체 직접 설치 경영 거나 법인 설립 경영 기업 운영 사항 경영...  \n",
      "1   [총칙 목적 은행 운영 도모 자금 중개 기능 효율 높이 예금 보호 신용 질서 유지 ...  \n",
      "2   [총칙 목적 수산업 제도 정함 수산 자원 수면 종합 이용 지속 수산업 발전 도모 국...  \n",
      "3   [목적 교육기본법 재능 사람 조기 발굴 능력 소질 교육 실시 개인 잠재력 계발 개인...  \n",
      "4   [목적 지방자치단체 설치 기금 관리 운용 기본 사항 규정 지방자치단체 기금 운용 성...  \n",
      "..                                                ...  \n",
      "80  [총칙 목적 건설 기계 등록 검사 형식 승인 건설 기계 사업 건설 기계 조종사 면허...  \n",
      "81  [총칙 목적 공동 유대 바탕 신용 협동 조직 육성 구성원 경제 사회 지위 향상 지역...  \n",
      "82  [목적 대학 도서관 설립 운영 지원 사항 규정 대학 도서관 진흥 대학 교육 연구 경...  \n",
      "83  [총칙 목적 농어 발생 농작물 임산물 양식 수산물 가축 농어 시설 물의 피해 손해 ...  \n",
      "84  [총칙 목적 건축 국가 지방자치단체 국민 책무 건축 정책 수립 시행 규정 건축 문화...  \n",
      "\n",
      "[85 rows x 5 columns]\n",
      "\n",
      "--- 0번 토픽의 주요 키워드 ---\n",
      "[('금융', np.float64(0.056819766045008144)), ('투자', np.float64(0.03345082247221737)), ('회사', np.float64(0.031131748644723428)), ('집합', np.float64(0.023170335057888094)), ('증권', np.float64(0.022440407420994447)), ('은행', np.float64(0.01895285089514944)), ('신탁', np.float64(0.01851708813012768)), ('발행', np.float64(0.01597829581563593)), ('주식', np.float64(0.015722290887860424)), ('거래', np.float64(0.015525976076845228))]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 49\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(topic_model\u001b[38;5;241m.\u001b[39mget_topic(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# --- 그룹별 토픽 분석 ---\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# 1. 각 법령에 토픽 ID와 과목 정보 추가\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m df_topics \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_document_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlaw_names_for_topic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m df_topics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m과목\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_topics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(law_to_subject)\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m기타\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# 2. 각 과목 그룹별로 어떤 토픽이 주로 나타나는지 시각화\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# 이 시각화는 Jupyter Notebook 환경에서 가장 잘 보입니다.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\silve\\miniconda3\\envs\\bylaw\\lib\\site-packages\\bertopic\\_bertopic.py:1786\u001b[0m, in \u001b[0;36mBERTopic.get_document_info\u001b[1;34m(self, docs, df, metadata)\u001b[0m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1785\u001b[0m     document_info \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m-> 1786\u001b[0m     \u001b[43mdocument_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDocument\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m docs\n\u001b[0;32m   1787\u001b[0m     document_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopics_\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# from bertopic import BERTopic\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from konlpy.tag import Okt\n",
    "# import os\n",
    "# # --- 데이터 준비 ---\n",
    "# # 1. 전처리된 텍스트 로드\n",
    "# preprocessed_text_dir = '법령_전처리_텍스트'\n",
    "# docs = []\n",
    "# law_names_for_topic = []\n",
    "# for filename in os.listdir(preprocessed_text_dir):\n",
    "#     if filename.endswith('.txt'):\n",
    "#         law_names_for_topic.append(filename[:-4])\n",
    "#         with open(os.path.join(preprocessed_text_dir, filename), 'r', encoding='utf-8') as f:\n",
    "#             docs.append(f.read())\n",
    "\n",
    "# # 2. 분석 대상 그룹 정의 (변호사 시험 과목 기준)\n",
    "# # (public_laws, civil_laws, criminal_laws 리스트가 메모리에 있다고 가정)\n",
    "# law_to_subject = {law: '공법' for law in public_laws}\n",
    "# law_to_subject.update({law: '민사법' for law in civil_laws})\n",
    "# law_to_subject.update({law: '형사법' for law in criminal_laws})\n",
    "\n",
    "# # --- 토픽 모델링 실행 ---\n",
    "# # 1. 한국어 명사 추출을 위한 벡터라이저 설정\n",
    "# okt = Okt()\n",
    "# vectorizer = CountVectorizer(tokenizer=okt.nouns, max_features=3000)\n",
    "\n",
    "# # 2. BERTopic 모델 초기화\n",
    "# # min_topic_size: 토픽을 구성하기 위한 최소 문서(법령) 수\n",
    "# topic_model = BERTopic(embedding_model=\"jhgan/ko-sbert-nli\",\n",
    "#                        vectorizer_model=vectorizer,\n",
    "#                        min_topic_size=5,\n",
    "#                        verbose=True)\n",
    "\n",
    "# # 3. 모델 학습 및 토픽 추출\n",
    "# # 시간이 매우 오래 걸릴 수 있습니다. ⏳\n",
    "# topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "# # 4. 결과 확인\n",
    "# print(\"\\n--- BERTopic 분석 결과 ---\")\n",
    "# # 가장 자주 등장하는 토픽들\n",
    "# print(topic_model.get_topic_info())\n",
    "\n",
    "# # 특정 토픽의 키워드 확인 (예: 0번 토픽)\n",
    "# print(\"\\n--- 0번 토픽의 주요 키워드 ---\")\n",
    "# print(topic_model.get_topic(0))\n",
    "\n",
    "# # --- 그룹별 토픽 분석 ---\n",
    "# # 1. 각 법령에 토픽 ID와 과목 정보 추가\n",
    "# df_topics = topic_model.get_document_info(docs, law_names_for_topic)\n",
    "# df_topics['과목'] = df_topics['Name'].map(law_to_subject).fillna('기타')\n",
    "\n",
    "# # 2. 각 과목 그룹별로 어떤 토픽이 주로 나타나는지 시각화\n",
    "# # 이 시각화는 Jupyter Notebook 환경에서 가장 잘 보입니다.\n",
    "# fig = topic_model.visualize_topics_by_class(\n",
    "#     df_topics,\n",
    "#     top_n_topics=10, # 상위 10개 토픽만 시각화\n",
    "#     custom_labels=True\n",
    "# )\n",
    "# fig.show() # 대화형 차트 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9edc94e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
