{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbc991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'법령별 csv 저장 중복제거' 폴더의 CSV 파일들을 읽어 '법령_통합텍스트' 폴더에 TXT 파일로 통합합니다.\n",
      "통합 대상 컬럼: ['조문내용', '항', '호', '목']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:20<00:00, 71.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "작업 완료! 모든 법령이 '법령_통합텍스트' 폴더에 .txt 파일로 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # 원본 CSV 파일들이 있는 소스 디렉토리\n",
    "# source_dir = '법령별 csv 저장 중복제거'\n",
    "\n",
    "# # 생성된 .txt 파일들을 저장할 출력 디렉토리\n",
    "# output_dir = '법령_통합텍스트'\n",
    "\n",
    "# # 합칠 대상 컬럼 목록\n",
    "# # ★ 만약 다른 컬럼도 추가하고 싶다면 이 리스트에 추가하세요.\n",
    "# columns_to_combine = ['조문내용', '항', '호', '목']\n",
    "\n",
    "# # 출력 디렉토리 생성 (이미 존재하면 넘어감)\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# print(f\"'{source_dir}' 폴더의 CSV 파일들을 읽어 '{output_dir}' 폴더에 TXT 파일로 통합합니다.\")\n",
    "# print(f\"통합 대상 컬럼: {columns_to_combine}\")\n",
    "\n",
    "# # 소스 디렉토리의 모든 파일에 대해 반복 작업\n",
    "# if not os.path.isdir(source_dir):\n",
    "#     print(f\"오류: 원본 폴더 '{source_dir}'를 찾을 수 없습니다. 경로를 확인해주세요.\")\n",
    "# else:\n",
    "#     for filename in tqdm(os.listdir(source_dir)):\n",
    "#         if filename.endswith('.csv'):\n",
    "#             try:\n",
    "#                 source_path = os.path.join(source_dir, filename)\n",
    "#                 df = pd.read_csv(source_path, sep='\\t')\n",
    "\n",
    "#                 # 실제 파일에 존재하는 컬럼만 필터링\n",
    "#                 existing_columns = [col for col in columns_to_combine if col in df.columns]\n",
    "\n",
    "#                 # 해당 컬럼들의 빈 값(NaN)을 빈 문자열('')로 대체\n",
    "#                 df[existing_columns] = df[existing_columns].fillna('').astype(str)\n",
    "\n",
    "#                 # 각 행(row)별로 존재하는 컬럼 내용을 공백으로 이어붙임\n",
    "#                 combined_series = df[existing_columns].apply(lambda row: ' '.join(row.values), axis=1)\n",
    "\n",
    "#                 # 법령 전체의 텍스트를 하나의 문자열로 합침 (각 행은 줄바꿈으로 구분)\n",
    "#                 full_text = '\\n'.join(combined_series)\n",
    "\n",
    "#                 # 출력 파일 경로 설정 (예: '가사소송법.csv' -> '가사소송법.txt')\n",
    "#                 output_filename = filename.replace('.csv', '.txt')\n",
    "#                 output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "#                 # 통합된 텍스트를 .txt 파일로 저장\n",
    "#                 with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#                     f.write(full_text)\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"오류 발생: {filename} 처리 중 문제 발생 - {e}\")\n",
    "\n",
    "#     print(f\"\\n작업 완료! 모든 법령이 '{output_dir}' 폴더에 .txt 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6cc9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\bylaw\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okt 토크나이저를 사용합니다.\n"
     ]
    }
   ],
   "source": [
    "# # ==============================================================================\n",
    "# # 1. 라이브러리 및 환경 설정\n",
    "# # ==============================================================================\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm  # 진행 상황을 시각적으로 보여주는 라이브러리\n",
    "\n",
    "# # --- 텍스트 처리를 위한 라이브러리 ---\n",
    "# from konlpy.tag import Okt # Okt이 설치되지 않았다면 Okt로 변경: from konlpy.tag import Okt\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# # --- 딥러닝 및 유사도 계산을 위한 라이브러리 ---\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import torch\n",
    "\n",
    "# # tqdm을 pandas의 apply와 함께 사용하기 위해 필요한 설정\n",
    "# tqdm.pandas()\n",
    "\n",
    "# # Okt 초기화 (Okt 설치 경로에 따라 필요시 인자 추가)\n",
    "# # okt를 사용할 경우: tokenizer = Okt()\n",
    "# try:\n",
    "#     tokenizer = Okt()\n",
    "#     print(\"Okt 토크나이저를 사용합니다.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Okt 로드 실패: {e}\")\n",
    "#     print(\"Okt 토크나이저로 대체합니다. 처리 속도가 느릴 수 있습니다.\")\n",
    "#     from konlpy.tag import Okt\n",
    "#     tokenizer = Okt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3790aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "과목별 법령 목록 로드 완료.\n",
      "'법령_통합텍스트' 폴더에서 전체 법령 텍스트를 로드합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:00<00:00, 3038.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 법령 데이터 로드 완료: 총 1500개 법령\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# from konlpy.tag import Mecab\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# # (이하 필요한 라이브러리들)\n",
    "\n",
    "# try:\n",
    "#     # ★ 탭으로 분리된 과목 목록 파일을 읽도록 sep='\\t' 추가\n",
    "#     public_laws = pd.read_csv('변호사시험_출제대상_부속법령(공법).csv')['법령명'].tolist()\n",
    "#     civil_laws = pd.read_csv('변호사시험_출제대상_부속법령(민사법).csv')['법령명'].tolist()\n",
    "#     criminal_laws = pd.read_csv('변호사시험_출제대상_부속법령(형사법).csv')['법령명'].tolist()\n",
    "#     print(\"과목별 법령 목록 로드 완료.\")\n",
    "# except FileNotFoundError as e:\n",
    "#     print(f\"오류: 과목별 법령 목록 파일을 찾을 수 없습니다. ({e.filename})\")\n",
    "#     exit() # 스크립트에서는 주석 해제\n",
    "\n",
    "# # --- 전체 법령 데이터 로드 (생성된 .txt 파일 로드) ---\n",
    "# all_laws_dir = '법령_통합텍스트' # ★ .txt 파일들이 저장된 폴더\n",
    "# all_laws_data = []\n",
    "\n",
    "\n",
    "# print(f\"'{all_laws_dir}' 폴더에서 전체 법령 텍스트를 로드합니다...\")\n",
    "# if not os.path.isdir(all_laws_dir):\n",
    "#     print(f\"오류: '{all_laws_dir}' 폴더를 찾을 수 없습니다. 1단계 코드를 먼저 실행했는지 확인해주세요.\")\n",
    "#     exit()\n",
    "\n",
    "# for file_name in tqdm(os.listdir(all_laws_dir)):\n",
    "#     if file_name.endswith('.txt'):\n",
    "#         law_name = file_name[:-4]  # '.txt' 확장자 제거\n",
    "#         file_path = os.path.join(all_laws_dir, file_name)\n",
    "#         try:\n",
    "#             with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#                 content = f.read()\n",
    "#             all_laws_data.append({'법령명': law_name, '내용': content})\n",
    "#         except Exception as e:\n",
    "#             print(f\"에러: {file_name} 파일 처리 중 오류 발생 - {e}\")\n",
    "\n",
    "# df_all_laws = pd.DataFrame(all_laws_data)\n",
    "# print(f\"전체 법령 데이터 로드 완료: 총 {len(df_all_laws)}개 법령\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a700194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. 데이터 전처리 시작 (명사 추출) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [11:54<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 전처리 완료.\n",
      "                                        법령명  \\\n",
      "0                10ㆍ27법난 피해자의 명예회복 등에 관한 법률   \n",
      "1  10ㆍ29이태원참사 피해자 권리보장과 진상규명 및 재발방지를 위한 특별법   \n",
      "2                     112신고의 운영 및 처리에 관한 법률   \n",
      "3                           119구조ㆍ구급에 관한 법률   \n",
      "4                   119긴급신고의 관리 및 운영에 관한 법률   \n",
      "\n",
      "                                              내용_전처리  \n",
      "0  목적 법난 관련 피해 사람과 불교 명예 회복 인권 신장 국민 화합 이바지 목적 정의...  \n",
      "1  총칙 목적 이태원 참사 발생 원인 수습 과정 후속 조치 사실관계 책임 소재 진상 희...  \n",
      "2  총칙 목적 신고 운영 처리 사항 규정 범죄 각종 사건 사고 상황 국민 생명 신체 재...  \n",
      "3  총칙 목적 화재 재난 재해 테러 상황 구조 구급 효율 운영 사항 규정 국가 구조 구...  \n",
      "4  총칙 목적 화재 재난 재해 구조 구급 상황 긴급 신고 관리 운영 사항 신고 개인정보...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [11:48<00:00,  2.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 전처리 완료.\n",
      "\n",
      "전처리된 텍스트를 '법령_전처리_텍스트' 폴더에 개별 저장합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:02<00:00, 558.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "작업 완료! 모든 전처리된 법령이 '법령_전처리_텍스트' 폴더에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 3. 데이터 전처리 (형태소 분석 및 명사 추출)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 3. 데이터 전처리 시작 (명사 추출) ---\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Mecab을 이용해 텍스트에서 명사만 추출하고 한 글자 단어는 제거\"\"\"\n",
    "    try:\n",
    "        # Mecab 사용 시: nouns = tokenizer.nouns(text)\n",
    "        # Okt 사용 시: nouns = tokenizer.nouns(text)\n",
    "        nouns = tokenizer.nouns(str(text))\n",
    "        # 한 글자 명사 제거 후 공백으로 연결\n",
    "        return ' '.join([noun for noun in nouns if len(noun) > 1])\n",
    "    except Exception as e:\n",
    "        # print(f\"전처리 오류 발생: {e}, 원문: {text[:30]}\")\n",
    "        return \"\" # 오류 발생 시 빈 문자열 반환\n",
    "\n",
    "# '내용' 컬럼에 전처리 함수 적용. 시간이 다소 소요될 수 있습니다.\n",
    "df_all_laws['내용_전처리'] = df_all_laws['내용'].progress_apply(preprocess_text)\n",
    "print(\"데이터 전처리 완료.\")\n",
    "print(df_all_laws[['법령명', '내용_전처리']].head())\n",
    "\n",
    "df_all_laws['내용_전처리'] = df_all_laws['내용'].progress_apply(preprocess_text)\n",
    "print(\"데이터 전처리 완료.\")\n",
    "\n",
    "# --- ★★★ 전처리 결과를 개별 txt 파일로 저장 (이 부분을 추가) ★★★ ---\n",
    "\n",
    "# 전처리된 파일들을 저장할 새 폴더 이름\n",
    "preprocessed_output_dir = '법령_전처리_텍스트' \n",
    "\n",
    "# 새 폴더 생성\n",
    "os.makedirs(preprocessed_output_dir, exist_ok=True)\n",
    "print(f\"\\n전처리된 텍스트를 '{preprocessed_output_dir}' 폴더에 개별 저장합니다...\")\n",
    "\n",
    "# 데이터프레임을 한 줄씩 순회하며 파일로 저장\n",
    "for index, row in tqdm(df_all_laws.iterrows(), total=df_all_laws.shape[0]):\n",
    "    law_name = row['법령명']\n",
    "    preprocessed_content = row['내용_전처리']\n",
    "    \n",
    "    # 출력 파일 경로 설정\n",
    "    output_path = os.path.join(preprocessed_output_dir, f\"{law_name}.txt\")\n",
    "    \n",
    "    # 전처리된 내용을 .txt 파일로 저장\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(preprocessed_content)\n",
    "\n",
    "print(f\"\\n작업 완료! 모든 전처리된 법령이 '{preprocessed_output_dir}' 폴더에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f55383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'법령_전처리_텍스트' 폴더에서 전처리된 법령 텍스트를 로드합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5502/5502 [00:00<00:00, 11510.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전처리 데이터 로딩 완료: 총 5502개 법령\n",
      "\n",
      "TF-IDF 벡터화를 진행합니다...\n",
      "'민법'과의 유사도 계산 완료.\n",
      "'형법'과의 유사도 계산 완료.\n",
      "'행정기본법'과의 유사도 계산 완료.\n",
      "\n",
      "\n",
      "==================================================\n",
      "                 유사도 분석 결과 확인\n",
      "==================================================\n",
      "\n",
      "\n",
      "--- '민법'과 가장 유사한 법령 TOP 10 ---\n",
      "               법령명   민법_유사도\n",
      "            가사소송규칙 0.517947\n",
      "             가사소송법 0.514872\n",
      "             민사집행법 0.353149\n",
      "       후견등기에 관한 법률 0.337079\n",
      "              국제사법 0.320565\n",
      "            민사집행규칙 0.318835\n",
      "채무자 회생 및 파산에 관한 법률 0.316726\n",
      "                상법 0.308696\n",
      "       후견등기에 관한 규칙 0.298736\n",
      " 가족관계의 등록 등에 관한 법률 0.281660\n",
      "\n",
      "\n",
      "--- '형법'과 가장 유사한 법령 TOP 10 ---\n",
      "                             법령명   형법_유사도\n",
      "                             군형법 0.635891\n",
      "              특정범죄 가중처벌 등에 관한 법률 0.604259\n",
      "                           국가보안법 0.527538\n",
      "                폭력행위 등 처벌에 관한 법률 0.473335\n",
      "            특정경제범죄 가중처벌 등에 관한 법률 0.374519\n",
      "                           밀항단속법 0.368587\n",
      "               보건범죄 단속에 관한 특별조치법 0.336398\n",
      "             성폭력범죄의 처벌 등에 관한 특례법 0.328000\n",
      "선박 및 해상구조물에 대한 위해행위의 처벌 등에 관한 법률 0.306891\n",
      "                         조세범 처벌법 0.301599\n",
      "\n",
      "\n",
      "--- '행정기본법'과 가장 유사한 법령 TOP 10 ---\n",
      "                                법령명  행정기본법_유사도\n",
      "                          행정기본법 시행령   0.671484\n",
      "                              행정절차법   0.642339\n",
      "                          질서위반행위규제법   0.483703\n",
      "                          행정절차법 시행령   0.461356\n",
      "                      질서위반행위규제법 시행령   0.435927\n",
      "                              행정소송법   0.429151\n",
      "    공공재정 부정청구 금지 및 부정이익 환수 등에 관한 법률   0.400343\n",
      "공공재정 부정청구 금지 및 부정이익 환수 등에 관한 법률 시행령   0.343356\n",
      "                              행정심판법   0.319364\n",
      "수산관계법령 위반행위에 대한 행정처분의 기준과 절차에 관한 규칙   0.304308\n",
      "\n",
      "\n",
      "✅ 모든 분석 결과가 'tf_idf_전법령_결과_현역.csv' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- 1. 전처리된 데이터 로드 ---\n",
    "preprocessed_text_dir = '법령_전처리_텍스트'\n",
    "all_laws_data = []\n",
    "\n",
    "print(f\"'{preprocessed_text_dir}' 폴더에서 전처리된 법령 텍스트를 로드합니다...\")\n",
    "for filename in tqdm(os.listdir(preprocessed_text_dir)):\n",
    "    if filename.endswith('.txt'):\n",
    "        law_name = filename[:-4]\n",
    "        file_path = os.path.join(preprocessed_text_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        all_laws_data.append({\n",
    "            '법령명': law_name,\n",
    "            '내용_전처리': content\n",
    "        })\n",
    "\n",
    "df_laws = pd.DataFrame(all_laws_data)\n",
    "print(f\"\\n전처리 데이터 로딩 완료: 총 {len(df_laws)}개 법령\")\n",
    "\n",
    "\n",
    "# --- 2. TF-IDF 벡터화 ---\n",
    "print(\"\\nTF-IDF 벡터화를 진행합니다...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, min_df=5)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(df_laws['내용_전처리'])\n",
    "\n",
    "\n",
    "# --- 3. 유사도 계산 ---\n",
    "benchmark_laws = ['민법', '형법', '행정기본법']\n",
    "results_df = df_laws.copy()\n",
    "\n",
    "for law_name in benchmark_laws:\n",
    "    try:\n",
    "        target_idx = df_laws.index[df_laws['법령명'] == law_name].tolist()[0]\n",
    "        target_vector = tfidf_vectors[target_idx]\n",
    "        sim_scores = cosine_similarity(tfidf_vectors, target_vector)\n",
    "        results_df[f'{law_name}_유사도'] = sim_scores\n",
    "        print(f\"'{law_name}'과의 유사도 계산 완료.\")\n",
    "\n",
    "    except IndexError:\n",
    "        print(f\"오류: 기준 법률 '{law_name}'을 찾을 수 없습니다.\")\n",
    "\n",
    "\n",
    "# --- 4. 결과 확인 ---\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"                 유사도 분석 결과 확인\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for law_name in benchmark_laws:\n",
    "    sim_col = f'{law_name}_유사도'\n",
    "    if sim_col in results_df.columns:\n",
    "        top_10 = results_df[results_df['법령명'] != law_name].nlargest(10, sim_col)\n",
    "        print(f\"\\n\\n--- '{law_name}'과 가장 유사한 법령 TOP 10 ---\")\n",
    "        print(top_10[['법령명', sim_col]].to_string(index=False))\n",
    "\n",
    "\n",
    "# --- 5. 최종 결과 저장 ---\n",
    "output_filename = 'tf_idf_전법령_결과_현역.csv'\n",
    "results_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n\\n✅ 모든 분석 결과가 '{output_filename}' 파일로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96e7bb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\silve\\anaconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'법령_통합텍스트(현역)' 폴더에서 원본 법령 텍스트를 로드합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5502/5502 [00:00<00:00, 7253.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "원본 데이터 로딩 완료: 총 5502개 법령\n",
      "\n",
      "SBERT 벡터화를 진행합니다. (시간이 많이 소요될 수 있습니다 ⏳)\n",
      "SBERT 분석에 사용할 장치: CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 172/172 [00:22<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'민법'과의 유사도 계산 완료.\n",
      "'형법'과의 유사도 계산 완료.\n",
      "'행정기본법'과의 유사도 계산 완료.\n",
      "\n",
      "\n",
      "==================================================\n",
      "              SBERT 기반 유사도 분석 결과 확인\n",
      "==================================================\n",
      "\n",
      "\n",
      "--- '민법'과 가장 유사한 법령 TOP 10 (SBERT) ---\n",
      "                    법령명  민법_유사도_SBERT\n",
      "                  법원조직법      0.834385\n",
      "                 행정소송규칙      0.816781\n",
      "                 민사소송규칙      0.816720\n",
      "대법원 공직자윤리위원회의 권한에 관한 규칙      0.815048\n",
      "                 가사소송규칙      0.814355\n",
      "                  형사소송법      0.804145\n",
      "                     상법      0.802892\n",
      "            민사소송 등 인지규칙      0.802111\n",
      "           법원행정처 행정심판규칙      0.801739\n",
      "                 민사집행규칙      0.801647\n",
      "\n",
      "\n",
      "--- '형법'과 가장 유사한 법령 TOP 10 (SBERT) ---\n",
      "                         법령명  형법_유사도_SBERT\n",
      "                 경범죄 처벌법 시행령      0.868211\n",
      "      범죄인인도법에의한인도심사등의절차에관한규칙      0.842682\n",
      "                         사면법      0.839862\n",
      "                경범죄 처벌법 시행규칙      0.833647\n",
      "  스토킹범죄 사건의 심리 및 재판 등에 관한 규칙      0.829639\n",
      "범죄수익은닉의 규제 및 처벌 등에 관한 법률 시행령      0.826938\n",
      "                     경범죄 처벌법      0.817388\n",
      "                       법관징계법      0.817092\n",
      "                   경찰공무원 징계령      0.815050\n",
      "          특정강력범죄의 처벌에 관한 특례법      0.814406\n",
      "\n",
      "\n",
      "--- '행정기본법'과 가장 유사한 법령 TOP 10 (SBERT) ---\n",
      "                     법령명  행정기본법_유사도_SBERT\n",
      "                   행정절차법         0.942872\n",
      "                  법제처 직제         0.937390\n",
      "  헌법재판소규칙 등의 입법절차에 관한 규칙         0.931746\n",
      "               법제업무 운영규정         0.931135\n",
      "                    법무사법         0.929496\n",
      "                   행정소송법         0.929410\n",
      "            민원 처리에 관한 법률         0.928593\n",
      "                    행정사법         0.927740\n",
      "       공익법무관에 관한 법률 시행규칙         0.927109\n",
      "대법원규칙 등의 제ㆍ개정절차 등에 관한 규칙         0.923912\n",
      "\n",
      "\n",
      "✅ 모든 SBERT 분석 결과가 'sbert_전법령_결과_현역.csv' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- 1. 원본 텍스트 데이터 로드 ---\n",
    "# SBERT는 원본 텍스트를 사용하므로, 원본 .txt 파일이 있는 폴더를 지정합니다.\n",
    "original_text_dir = '법령_통합텍스트(현역)'\n",
    "all_laws_data = []\n",
    "\n",
    "print(f\"'{original_text_dir}' 폴더에서 원본 법령 텍스트를 로드합니다...\")\n",
    "if not os.path.isdir(original_text_dir):\n",
    "    print(f\"오류: '{original_text_dir}' 폴더를 찾을 수 없습니다. 원본 txt 통합 파일이 준비되어 있는지 확인해주세요.\")\n",
    "    exit()\n",
    "\n",
    "for filename in tqdm(os.listdir(original_text_dir)):\n",
    "    if filename.endswith('.txt'):\n",
    "        law_name = filename[:-4]\n",
    "        file_path = os.path.join(original_text_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        all_laws_data.append({\n",
    "            '법령명': law_name,\n",
    "            '내용': content  # SBERT는 전처리 전 '내용' 컬럼을 사용\n",
    "        })\n",
    "\n",
    "df_laws = pd.DataFrame(all_laws_data)\n",
    "print(f\"\\n원본 데이터 로딩 완료: 총 {len(df_laws)}개 법령\")\n",
    "\n",
    "\n",
    "# --- 2. SBERT 벡터화 ---\n",
    "print(\"\\nSBERT 벡터화를 진행합니다. (시간이 많이 소요될 수 있습니다 ⏳)\")\n",
    "# GPU 자동 감지\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"SBERT 분석에 사용할 장치: {device.upper()}\")\n",
    "\n",
    "# SBERT 모델 로드\n",
    "sbert_model = SentenceTransformer(\n",
    "    'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
    "    device=device\n",
    ")\n",
    "# 원본 '내용' 컬럼을 인코딩\n",
    "sbert_vectors = sbert_model.encode(\n",
    "    df_laws['내용'].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "\n",
    "# --- 3. 유사도 계산 ---\n",
    "benchmark_laws = ['민법', '형법', '행정기본법']\n",
    "results_df = df_laws.copy()\n",
    "\n",
    "for law_name in benchmark_laws:\n",
    "    try:\n",
    "        # 기준 법률의 인덱스 찾기\n",
    "        target_idx = df_laws.index[df_laws['법령명'] == law_name].tolist()[0]\n",
    "        # 해당 인덱스의 SBERT 벡터 추출\n",
    "        target_vector = sbert_vectors[target_idx]\n",
    "\n",
    "        # 전체 SBERT 벡터와 기준 벡터 간의 코사인 유사도 계산\n",
    "        sim_scores = cosine_similarity(sbert_vectors, target_vector.reshape(1, -1))\n",
    "\n",
    "        # 결과를 데이터프레임의 새 컬럼으로 추가\n",
    "        results_df[f'{law_name}_유사도_SBERT'] = sim_scores\n",
    "        print(f\"'{law_name}'과의 유사도 계산 완료.\")\n",
    "\n",
    "    except IndexError:\n",
    "        print(f\"오류: 기준 법률 '{law_name}'을 찾을 수 없습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"'{law_name}' 처리 중 오류 발생: {e}\")\n",
    "\n",
    "\n",
    "# --- 4. 결과 확인 ---\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"              SBERT 기반 유사도 분석 결과 확인\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for law_name in benchmark_laws:\n",
    "    sim_col = f'{law_name}_유사도_SBERT'\n",
    "    if sim_col in results_df.columns:\n",
    "        # 자기 자신을 제외하고 상위 10개 추출\n",
    "        top_10 = results_df[results_df['법령명'] != law_name].nlargest(10, sim_col)\n",
    "        print(f\"\\n\\n--- '{law_name}'과 가장 유사한 법령 TOP 10 (SBERT) ---\")\n",
    "        print(top_10[['법령명', sim_col]].to_string(index=False))\n",
    "\n",
    "\n",
    "# --- 5. 최종 결과 저장 ---\n",
    "output_filename = 'sbert_전법령_결과_현역.csv'\n",
    "# 원본 '내용' 컬럼은 용량이 크므로 제외하고 저장\n",
    "results_df.drop(columns=['내용']).to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n\\n✅ 모든 SBERT 분석 결과가 '{output_filename}' 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119df133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
